{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification con AutoKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "np.random.seed(5)\n",
    "from numpy import asarray\n",
    "\n",
    "import autokeras\n",
    "from autokeras import StructuredDataClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 1: Texto Limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          AFR PLAN OBRAS EQUIPAMIENTOS SERVICIOS 2022\n",
       "1                       312 FONDO EROGACIÓN PLAN OBRAS\n",
       "2    AFR PLAN OBRAS EQUIPAMIENTO SERVICIOS 2022 RUR...\n",
       "3    DCTO 119 AFR PGO HAB ASIG FLIAR ENE CTA 200982014\n",
       "4    DCTO 120 AFR PGO HAB ASIG FLIAR ENE CTA 200981813\n",
       "Name: texto_limpio, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/df_final.csv\", sep=\";\")\n",
    "df['texto_limpio'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Complete [00h 00m 01s]\n",
      "\n",
      "Best val_loss So Far: 0.24450507760047913\n",
      "Total elapsed time: 00h 30m 14s\n",
      "Epoch 1/10\n",
      "1160/1160 [==============================] - 169s 145ms/step - loss: 0.8278 - accuracy: 0.7679\n",
      "Epoch 2/10\n",
      "1160/1160 [==============================] - 167s 144ms/step - loss: 0.2317 - accuracy: 0.9304\n",
      "Epoch 3/10\n",
      "1160/1160 [==============================] - 168s 145ms/step - loss: 0.1576 - accuracy: 0.9500\n",
      "Epoch 4/10\n",
      "1160/1160 [==============================] - 165s 142ms/step - loss: 0.1201 - accuracy: 0.9611\n",
      "Epoch 5/10\n",
      "1160/1160 [==============================] - 166s 143ms/step - loss: 0.0981 - accuracy: 0.9675\n",
      "Epoch 6/10\n",
      "1160/1160 [==============================] - 166s 143ms/step - loss: 0.0811 - accuracy: 0.9726\n",
      "Epoch 7/10\n",
      "1160/1160 [==============================] - 169s 146ms/step - loss: 0.0707 - accuracy: 0.9764\n",
      "Epoch 8/10\n",
      "1160/1160 [==============================] - 167s 144ms/step - loss: 0.0655 - accuracy: 0.9775\n",
      "Epoch 9/10\n",
      "1160/1160 [==============================] - 171s 147ms/step - loss: 0.0591 - accuracy: 0.9796\n",
      "Epoch 10/10\n",
      "1160/1160 [==============================] - 167s 144ms/step - loss: 0.0534 - accuracy: 0.9808\n",
      "INFO:tensorflow:Assets written to: .\\text_classifier\\best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\text_classifier\\best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290/290 [==============================] - 12s 40ms/step - loss: 0.3242 - accuracy: 0.9361\n",
      "Precisión del modelo: 0.9360578060150146\n",
      "INFO:tensorflow:Assets written to: mi_mejor_modelo_autokeras\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mi_mejor_modelo_autokeras\\assets\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "\n",
    "# Asegúrate de tener las versiones más recientes\n",
    "print(f\"AutoKeras version: {ak.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "df = pd.read_csv(\"../datasets/df_final.csv\", sep=\";\")\n",
    "df['texto_limpio'] = df['texto_limpio'].fillna(\"RES\")\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['texto_limpio'], df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convertir las series de pandas a arrays de NumPy\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Crear el clasificador de texto de AutoKeras\n",
    "clf = ak.TextClassifier(\n",
    "    max_trials=4,  # Número de modelos a probar\n",
    "    overwrite=True\n",
    "    #max_tokens=20000  # Ajusta este valor según la longitud de tu texto\n",
    ")\n",
    "\n",
    "# Ajustar el modelo\n",
    "clf.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = clf.evaluate(X_test, y_test)\n",
    "print(f\"Precisión del modelo: {accuracy[1]}\")\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_model = clf.export_model()\n",
    "\n",
    "# Guardar el modelo\n",
    "best_model.save(\"mi_mejor_modelo_autokeras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " expand_last_dim (ExpandLas  (None, 1)                 0         \n",
      " tDim)                                                           \n",
      "                                                                 \n",
      " text_vectorization (TextVe  (None, 512)               0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 512, 64)           320064    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512, 64)           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 508, 256)          82176     \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 256)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                6939      \n",
      "                                                                 \n",
      " classification_head_1 (Sof  (None, 27)                0         \n",
      " tmax)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 474971 (1.81 MB)\n",
      "Trainable params: 474971 (1.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " expand_last_dim (ExpandLas  (None, 1)                 0         \n",
      " tDim)                                                           \n",
      "                                                                 \n",
      " text_vectorization (TextVe  (None, 512)               0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 512, 64)           320064    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512, 64)           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 508, 256)          82176     \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 256)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                6939      \n",
      "                                                                 \n",
      " classification_head_1 (Sof  (None, 27)                0         \n",
      " tmax)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 474971 (1.81 MB)\n",
      "Trainable params: 474971 (1.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded = tf.keras.models.load_model(\"mi_mejor_modelo_autokeras\", custom_objects=ak.CUSTOM_OBJECTS)\n",
    "\n",
    "loaded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 2: Descripción sin procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Complete [00h 00m 01s]\n",
      "\n",
      "Best val_loss So Far: 0.5009853839874268\n",
      "Total elapsed time: 00h 34m 10s\n",
      "Epoch 1/10\n",
      "1160/1160 [==============================] - 170s 145ms/step - loss: 1.1302 - accuracy: 0.6885\n",
      "Epoch 2/10\n",
      "1160/1160 [==============================] - 163s 140ms/step - loss: 0.5388 - accuracy: 0.8452\n",
      "Epoch 3/10\n",
      "1160/1160 [==============================] - 163s 140ms/step - loss: 0.4463 - accuracy: 0.8653\n",
      "Epoch 4/10\n",
      "1160/1160 [==============================] - 165s 142ms/step - loss: 0.4016 - accuracy: 0.8766\n",
      "Epoch 5/10\n",
      "1160/1160 [==============================] - 184s 159ms/step - loss: 0.3745 - accuracy: 0.8831\n",
      "Epoch 6/10\n",
      "1160/1160 [==============================] - 191s 165ms/step - loss: 0.3564 - accuracy: 0.8893\n",
      "Epoch 7/10\n",
      "1160/1160 [==============================] - 171s 147ms/step - loss: 0.3413 - accuracy: 0.8922\n",
      "Epoch 8/10\n",
      "1160/1160 [==============================] - 170s 147ms/step - loss: 0.3283 - accuracy: 0.8957\n",
      "Epoch 9/10\n",
      "1160/1160 [==============================] - 174s 150ms/step - loss: 0.3200 - accuracy: 0.8973\n",
      "Epoch 10/10\n",
      "1160/1160 [==============================] - 182s 157ms/step - loss: 0.3181 - accuracy: 0.8986\n",
      "INFO:tensorflow:Assets written to: .\\text_classifier\\best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\text_classifier\\best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290/290 [==============================] - 12s 38ms/step - loss: 0.5140 - accuracy: 0.8614\n",
      "Precisión del modelo: 0.8614405989646912\n",
      "INFO:tensorflow:Assets written to: autokeras_text_mining\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: autokeras_text_mining\\assets\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "\n",
    "# Asegúrate de tener las versiones más recientes\n",
    "print(f\"AutoKeras version: {ak.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "df = pd.read_csv(\"../datasets/df.csv\", sep=\";\",  encoding='latin1')\n",
    "df['Descripcion'] = df['Descripcion'].fillna(\"RES\")\n",
    "\n",
    "Class = list(df.Class.unique())\n",
    "clases = {val:Class.index(val) for val in Class}\n",
    "def get_class(val):\n",
    "    return clases[val]\n",
    "df['target'] = df['Class'].apply(get_class)\n",
    "df.drop(columns=['Class'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Descripcion'], df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convertir las series de pandas a arrays de NumPy\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Crear el clasificador de texto de AutoKeras\n",
    "clf = ak.TextClassifier(\n",
    "    max_trials=4,  # Número de modelos a probar\n",
    "    overwrite=True\n",
    "    #max_tokens=20000  # Ajusta este valor según la longitud de tu texto\n",
    ")\n",
    "\n",
    "# Ajustar el modelo\n",
    "clf.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = clf.evaluate(X_test, y_test)\n",
    "print(f\"Precisión del modelo: {accuracy[1]}\")\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_model = clf.export_model()\n",
    "\n",
    "# Guardar el modelo\n",
    "best_model.save(\"autokeras_text_mining\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 3: Texto limpio sin palabras repetidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Complete [00h 00m 01s]\n",
      "\n",
      "Best val_loss So Far: 0.25200486183166504\n",
      "Total elapsed time: 00h 29m 18s\n",
      "Epoch 1/10\n",
      "1160/1160 [==============================] - 165s 141ms/step - loss: 0.8702 - accuracy: 0.7531\n",
      "Epoch 2/10\n",
      "1160/1160 [==============================] - 171s 148ms/step - loss: 0.2534 - accuracy: 0.9252\n",
      "Epoch 3/10\n",
      "1160/1160 [==============================] - 192s 166ms/step - loss: 0.1681 - accuracy: 0.9484\n",
      "Epoch 4/10\n",
      "1160/1160 [==============================] - 192s 166ms/step - loss: 0.1277 - accuracy: 0.9589\n",
      "Epoch 5/10\n",
      "1160/1160 [==============================] - 189s 163ms/step - loss: 0.1066 - accuracy: 0.9651\n",
      "Epoch 6/10\n",
      "1160/1160 [==============================] - 196s 169ms/step - loss: 0.0866 - accuracy: 0.9700\n",
      "Epoch 7/10\n",
      "1160/1160 [==============================] - 224s 193ms/step - loss: 0.0775 - accuracy: 0.9734\n",
      "Epoch 8/10\n",
      "1160/1160 [==============================] - 207s 178ms/step - loss: 0.0721 - accuracy: 0.9749\n",
      "Epoch 9/10\n",
      "1160/1160 [==============================] - 182s 157ms/step - loss: 0.0653 - accuracy: 0.9766\n",
      "Epoch 10/10\n",
      "1160/1160 [==============================] - 191s 165ms/step - loss: 0.0600 - accuracy: 0.9789\n",
      "INFO:tensorflow:Assets written to: .\\text_classifier\\best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\text_classifier\\best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290/290 [==============================] - 12s 39ms/step - loss: 0.3303 - accuracy: 0.9321\n",
      "Precisión del modelo: 0.9320681691169739\n",
      "INFO:tensorflow:Assets written to: autokeras_modelo_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: autokeras_modelo_3\\assets\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "# Asegúrate de tener las versiones más recientes\n",
    "print(f\"AutoKeras version: {ak.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "df = pd.read_csv(\"../datasets/df_final.csv\", sep=\";\")\n",
    "df['texto_limpio'] = df['texto_limpio'].fillna(\"2023\")\n",
    "\n",
    "def eliminar_palabras(texto):\n",
    "    texto = texto.upper()\n",
    "    texto = re.findall(r\"(?!CTA)(?!RES)(?!PAGO)(?!AGO)(?!PAG)[A-Z0-9]{3,}\", texto)\n",
    "    texto = list(dict.fromkeys(texto))\n",
    "    texto = \" \".join(texto).strip()\n",
    "    return texto\n",
    "\n",
    "\n",
    "df[\"texto_limpio\"] = df[\"texto_limpio\"].apply(eliminar_palabras)\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['texto_limpio'], df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convertir las series de pandas a arrays de NumPy\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Crear el clasificador de texto de AutoKeras\n",
    "clf = ak.TextClassifier(\n",
    "    max_trials=4,  # Número de modelos a probar\n",
    "    overwrite=True\n",
    "    #max_tokens=20000  # Ajusta este valor según la longitud de tu texto\n",
    ")\n",
    "\n",
    "# Ajustar el modelo\n",
    "clf.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = clf.evaluate(X_test, y_test)\n",
    "print(f\"Precisión del modelo: {accuracy[1]}\")\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_model = clf.export_model()\n",
    "\n",
    "# Guardar el modelo\n",
    "best_model.save(\"autokeras_modelo_3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
