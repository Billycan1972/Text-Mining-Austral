{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "# Funciones auxiliares sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, KFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer, accuracy_score, balanced_accuracy_score, confusion_matrix, roc_curve, auc, accuracy_score, mean_squared_error, mean_absolute_error, r2_score, classification_report # Metricas\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Guardado de objetos en archivos joblib\n",
    "from joblib import load, dump\n",
    "\n",
    "# Optimizacion de hiperparametros\n",
    "import optuna\n",
    "from optuna.artifacts import FileSystemArtifactStore, upload_artifact\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subimos dos niveles para quedar en la carpeta que contiene input y lab2-mcd-austral\n",
    "BASE_DIR = './'\n",
    "\n",
    "#Salida de modelos entrenados\n",
    "PATH_TO_MODELS = os.path.join(BASE_DIR, \"work/models\")\n",
    "\n",
    "#Artefactos a subir a optuna\n",
    "PATH_TO_TEMP_FILES = os.path.join(BASE_DIR, \"work/optuna_temp_artifacts\")\n",
    "\n",
    "#Artefactos que optuna gestiona\n",
    "PATH_TO_OPTUNA_ARTIFACTS = os.path.join(BASE_DIR, \"work/optuna_artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ejercicio</th>\n",
       "      <th>Tipo_Cpbte</th>\n",
       "      <th>N°_Entrada</th>\n",
       "      <th>Entidad_Nº</th>\n",
       "      <th>Cod_Ret</th>\n",
       "      <th>Fte_Fin.</th>\n",
       "      <th>Cuit/DniOtros</th>\n",
       "      <th>Clase_Registro</th>\n",
       "      <th>Clase_Gasto</th>\n",
       "      <th>Glosa</th>\n",
       "      <th>Sueldo</th>\n",
       "      <th>texto_limpio</th>\n",
       "      <th>pesos</th>\n",
       "      <th>cuentas_sueldo</th>\n",
       "      <th>pesos_cuentas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>AF</td>\n",
       "      <td>137</td>\n",
       "      <td>25</td>\n",
       "      <td>217</td>\n",
       "      <td>10</td>\n",
       "      <td>710</td>\n",
       "      <td>ANT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RES 7/21 ANTICIPO SUB. Y SUBVEN. CTA 360000200...</td>\n",
       "      <td>0</td>\n",
       "      <td>ANTICIPO SUB SUBVEN</td>\n",
       "      <td>95</td>\n",
       "      <td>360000200981158</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>AF</td>\n",
       "      <td>138</td>\n",
       "      <td>25</td>\n",
       "      <td>202</td>\n",
       "      <td>10</td>\n",
       "      <td>710</td>\n",
       "      <td>ANT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RES 8/21 ANT. VIATICOS Y MOVIL.  CUENTA Nº3600...</td>\n",
       "      <td>0</td>\n",
       "      <td>ANT VIATICOS MOVIL CUENTA</td>\n",
       "      <td>93</td>\n",
       "      <td>360000200982335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Ejercicio Tipo_Cpbte  N°_Entrada  Entidad_Nº  Cod_Ret  \\\n",
       "0           0       2021         AF         137          25      217   \n",
       "1           1       2021         AF         138          25      202   \n",
       "\n",
       "   Fte_Fin.  Cuit/DniOtros Clase_Registro Clase_Gasto  \\\n",
       "0        10            710            ANT         NaN   \n",
       "1        10            710            ANT         NaN   \n",
       "\n",
       "                                               Glosa  Sueldo  \\\n",
       "0  RES 7/21 ANTICIPO SUB. Y SUBVEN. CTA 360000200...       0   \n",
       "1  RES 8/21 ANT. VIATICOS Y MOVIL.  CUENTA Nº3600...       0   \n",
       "\n",
       "                texto_limpio  pesos   cuentas_sueldo  pesos_cuentas  \n",
       "0        ANTICIPO SUB SUBVEN     95  360000200981158              4  \n",
       "1  ANT VIATICOS MOVIL CUENTA     93  360000200982335              0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv('../Text-Mining-Austral/dataset.csv',delimiter=';')\n",
    "df = pd.read_csv('dataset_pesos.csv',sep=';')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot encoding\n",
    "df.join(pd.get_dummies(df[[\"Tipo_Cpbte\"]]))\n",
    "df.drop(columns=[\"Tipo_Cpbte\"], inplace=True)\n",
    "\n",
    "df.join(pd.get_dummies(df[[\"Clase_Registro\"]]))\n",
    "df.drop(columns=[\"Clase_Registro\"], inplace=True)\n",
    "\n",
    "df.join(pd.get_dummies(df[[\"Clase_Gasto\"]]))\n",
    "df.drop(columns=[\"Clase_Gasto\"], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 12345\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# X = df.drop(columns = [\"Sueldo\",\"Glosa\",\"N°_Entrada\",\"Ejercicio\", \"Cod_Ret\"])\n",
    "X = df.drop(columns = [\"Sueldo\",\"Glosa\",\"N°_Entrada\",\"Ejercicio\", \"texto_limpio\", \"cuentas_sueldo\"])\n",
    "#X = df[['pesos']]\n",
    "y = df.Sueldo\n",
    "\n",
    "# División en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=SEED)\n",
    "\n",
    "# Combinar X_train y y_train en un solo DataFrame\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Combinar X_test y y_test en un solo DataFrame\n",
    "test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_es_gbc_objective(trial):\n",
    "\n",
    "    #Parametros para LightGBM\n",
    "    gbc_params = {      \n",
    "                       # 'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "                        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1.0),\n",
    "                       # 'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                        ##'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "                        #'subsample': trial.suggest_uniform('subsample', 0.5, 1.0)\n",
    "                        #'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "                        #'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None, 'auto']),\n",
    "                        #'loss': trial.suggest_categorical('loss', ['deviance', 'exponential']),\n",
    "                        } \n",
    "\n",
    "    #Voy a generar estimaciones de los 5 modelos del CV sobre los datos test y los acumulo en la matriz scores_ensemble\n",
    "    scores_ensemble = np.zeros((len(y_test),len(y_train.unique())))\n",
    "\n",
    "    #Score del 5 fold CV inicializado en 0\n",
    "    score_folds = 0\n",
    "\n",
    "    #Numero de splits del CV\n",
    "    n_splits = 5\n",
    "\n",
    "    #Objeto para hacer el split estratificado de CV\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    for i, (if_index, oof_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        \n",
    "        # Dataset in fold (donde entreno)\n",
    "        X_if, y_if = X_train.iloc[if_index], y_train.iloc[if_index]\n",
    "        \n",
    "        # Dataset Out of fold (donde mido la performance del CV)\n",
    "        X_oof, y_oof = X_train.iloc[oof_index], y_train.iloc[oof_index]\n",
    "\n",
    "        # Crear el modelo RandomForestClassifier con los parámetros sugeridos\n",
    "        gbc_model = GradientBoostingClassifier(**gbc_params, random_state=42)\n",
    "        \n",
    "        # Entrenar el modelo\n",
    "        gbc_model.fit(X_if, y_if)\n",
    "        \n",
    "        # Acumular los scores (probabilidades) de cada clase para cada uno de los modelos que determino en los folds\n",
    "        scores_ensemble += gbc_model.predict_proba(X_test)\n",
    "        \n",
    "        # Score del fold (registros de dataset train que en este fold quedan out of fold)\n",
    "        score_folds += accuracy_score(y_oof, gbc_model.predict(X_oof)) / n_splits\n",
    "\n",
    "\n",
    "    #Guardo prediccion del trial sobre el conjunto de test\n",
    "    # Genero nombre de archivo\n",
    "    predicted_filename = os.path.join(PATH_TO_TEMP_FILES,f'test_{trial.study.study_name}_{trial.number}.joblib')\n",
    "    # Copia del dataset para guardar la prediccion\n",
    "    predicted_df = test.copy()\n",
    "    # Genero columna pred con predicciones sumadas de los 5 folds\n",
    "    predicted_df['pred'] = [scores_ensemble[p,:] for p in range(scores_ensemble.shape[0])]\n",
    "    # Grabo dataframe en temp_artifacts\n",
    "    dump(predicted_df, predicted_filename)\n",
    "    # Indico a optuna que asocie el archivo generado al trial\n",
    "    upload_artifact(trial, predicted_filename, artifact_store)    \n",
    "\n",
    "\n",
    "    #Determino score en conjunto de test y asocio como metrica adicional en optuna\n",
    "    test_score = accuracy_score(y_test, scores_ensemble.argmax(axis=1))\n",
    "    trial.set_user_attr(\"test_score\", test_score)\n",
    "\n",
    "    #Devuelvo score del 5fold cv a optuna para que optimice en base a eso\n",
    "    return(score_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-10 12:38:31,351] A new study created in RDB with name: gbc con score con cuentas\n",
      "[I 2024-08-10 12:40:39,172] Trial 0 finished with value: 0.9807436536647812 and parameters: {'learning_rate': 0.2838521462594924}. Best is trial 0 with value: 0.9807436536647812.\n",
      "[I 2024-08-10 12:42:49,574] Trial 1 finished with value: 0.9623331120103464 and parameters: {'learning_rate': 0.01488214080774319}. Best is trial 0 with value: 0.9807436536647812.\n",
      "[I 2024-08-10 12:44:53,736] Trial 2 finished with value: 0.8815385374253708 and parameters: {'learning_rate': 0.0030929087617836905}. Best is trial 0 with value: 0.9807436536647812.\n"
     ]
    }
   ],
   "source": [
    "#Inicio el store de artefactos (archivos) de optuna\n",
    "artifact_store = FileSystemArtifactStore(base_path=PATH_TO_OPTUNA_ARTIFACTS)\n",
    "\n",
    "#Genero estudio\n",
    "study = optuna.create_study(direction='maximize',\n",
    "                            storage=\"sqlite:///sueldos2.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=\"gbc con score con cuentas\",\n",
    "                            load_if_exists = True)\n",
    "#Corro la optimizacion\n",
    "study.optimize(cv_es_gbc_objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
